{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ThelscienCerog\n",
      "CelnRealization\n",
      "\n",
      "fa\n",
      "‘« a\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def capture_image():\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        cv2.imshow('Press Space to Capture', frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord(' '):\n",
    "            cv2.imwrite('captured_image.jpg', frame)\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    # Load the image\n",
    "    img = cv2.imread(image_path)\n",
    "    \n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Apply thresholding\n",
    "    _, thresh = cv2.threshold(gray, 150, 255, cv2.THRESH_BINARY_INV)\n",
    "    \n",
    "    # Remove noise\n",
    "    kernel = np.ones((1, 1), np.uint8)\n",
    "    processed_img = cv2.dilate(thresh, kernel, iterations=1)\n",
    "    processed_img = cv2.erode(processed_img, kernel, iterations=1)\n",
    "    \n",
    "    # Save the processed image\n",
    "    processed_image_path = 'processed_image.jpg'\n",
    "    cv2.imwrite(processed_image_path, processed_img)\n",
    "    \n",
    "    return processed_image_path\n",
    "\n",
    "def extract_text_from_image(image_path):\n",
    "    img = Image.open(image_path)\n",
    "    text = pytesseract.image_to_string(img)\n",
    "    return text\n",
    "\n",
    "def save_text_to_file(text, file_path):\n",
    "    with open(file_path, 'w') as file:\n",
    "        file.write(text)\n",
    "\n",
    "capture_image()\n",
    "image_path = 'captured_image.jpg'\n",
    "processed_image_path = preprocess_image(image_path)\n",
    "extracted_text = extract_text_from_image(processed_image_path)\n",
    "print(extracted_text)\n",
    "\n",
    "# Save the extracted text to a file\n",
    "text_file_path = 'extracted_text.txt'\n",
    "save_text_to_file(extracted_text, text_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pprint import pprint\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_core.output_parsers import JsonOutputParser, StrOutputParser\n",
    "from langchain.schema import Document\n",
    "from langgraph.graph import END, StateGraph\n",
    "from typing_extensions import TypedDict\n",
    "from typing import List\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.embeddings import GPT4AllEmbeddings\n",
    "from langchain_community.document_loaders import FireCrawlLoader\n",
    "from langchain_community.vectorstores.utils import filter_complex_metadata\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.embeddings import GPT4AllEmbeddings\n",
    "from langchain_community.document_loaders import FireCrawlLoader\n",
    "from langchain_community.vectorstores.utils import filter_complex_metadata\n",
    "from langchain.docstore.document import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_llm='deepseek-r1:14b'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'when_to_take_it': {'description': 'Take this medicine exactly as prescribed by your doctor. Do not change the dosage or stop taking it without consulting your healthcare provider.'}, 'precautions': {'description': 'Inform your doctor if you have any allergies, especially to other diabetes medications. Also, let them know about any other medications or supplements you are taking. If you experience severe side effects like difficulty breathing, swelling of the face, lips, or tongue, seek immediate medical attention.'}, 'side_effects': {'description': 'Common side effects may include hypoglycemia (low blood sugar), which can cause symptoms like shakiness, sweating, dizziness, and confusion. Rare but serious side effects might involve an allergic reaction, leading to difficulty breathing or swelling of the face.'}, 'additional_advice': {'description': 'Monitor your blood sugar levels regularly as directed by your doctor. Maintain a healthy diet and exercise routine. Always carry a fast-acting carbohydrate source in case of hypoglycemia. Inform your healthcare provider if you experience any unusual symptoms or if your condition does not improve.'}}\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "# Initialize the ChatOLLama model\n",
    "llm = ChatOllama(model=local_llm, format=\"json\", temperature=0)\n",
    "\n",
    "# Define the prompt template correctly\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "    <|begin_of_text|><|start_header_id|>system<|end_header_id|> \n",
    "   You are a knowledgeable and compassionate doctor providing clear guidance on a patient's prescribed medicine.\n",
    "    Based on the given medicine description, provide:\n",
    "    \n",
    "    1. **When to Take It:** Clearly explain the best time and conditions under which the medicine should be taken (e.g., with food, before sleep, on an empty stomach).\n",
    "    2. **Precautions:** List important things the patient should be aware of before taking the medicine (e.g., allergies, interactions, conditions that may worsen).\n",
    "    3. **Side Effects:** Describe common and severe side effects in simple terms, and when the patient should seek medical attention.\n",
    "    4. **Additional Advice:** Provide any extra tips to ensure safe and effective use of the medicine.\n",
    "\n",
    "    Be clear, friendly, and reassuring so that the patient fully understands their medication.\n",
    "\n",
    "    Here is the medicine description:\n",
    "    <|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "    {context}\n",
    "    Here is the user question: {question}\n",
    "    <|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "    \"\"\",\n",
    "    input_variables=[\"question\", \"context\"]\n",
    ")\n",
    "\n",
    "# Initialize the retrieval grader with a correct pipeline\n",
    "retrieval_grader = prompt | llm | JsonOutputParser()\n",
    "\n",
    "# Define the user question and sample context\n",
    "question = \"Is there a possibility to get diabetics while being pregnant?\"\n",
    "context = \"Gestational diabetes is a condition where high blood sugar develops during pregnancy.\"\n",
    "\n",
    "# Use the retrieval grader to assess the context's relevance\n",
    "result = retrieval_grader.invoke({\"question\": question, \"context\": context})\n",
    "\n",
    "# Print the result\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
