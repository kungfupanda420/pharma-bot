{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def capture_image():\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        cv2.imshow('Press Space to Capture', frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord(' '):\n",
    "            cv2.imwrite('captured_image.jpg', frame)\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    # Load the image\n",
    "    img = cv2.imread(image_path)\n",
    "    \n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Apply thresholding\n",
    "    _, thresh = cv2.threshold(gray, 150, 255, cv2.THRESH_BINARY_INV)\n",
    "    \n",
    "    # Remove noise\n",
    "    kernel = np.ones((1, 1), np.uint8)\n",
    "    processed_img = cv2.dilate(thresh, kernel, iterations=1)\n",
    "    processed_img = cv2.erode(processed_img, kernel, iterations=1)\n",
    "    \n",
    "    # Save the processed image\n",
    "    processed_image_path = 'processed_image.jpg'\n",
    "    cv2.imwrite(processed_image_path, processed_img)\n",
    "    \n",
    "    return processed_image_path\n",
    "\n",
    "def extract_text_from_image(image_path):\n",
    "    img = Image.open(image_path)\n",
    "    text = pytesseract.image_to_string(img)\n",
    "    return text\n",
    "\n",
    "def save_text_to_file(text, file_path):\n",
    "    with open(file_path, 'w') as file:\n",
    "        file.write(text)\n",
    "\n",
    "capture_image()\n",
    "image_path = 'captured_image.jpg'\n",
    "processed_image_path = preprocess_image(image_path)\n",
    "extracted_text = extract_text_from_image(processed_image_path)\n",
    "print(extracted_text)\n",
    "\n",
    "# Save the extracted text to a file\n",
    "text_file_path = 'extracted_text.txt'\n",
    "save_text_to_file(extracted_text, text_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'config'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     15\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m llm\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# Load the LLaMA model\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m model = \u001b[43mload_llm\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# Read the text file\u001b[39;00m\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mextracted_text.txt\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mr\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 6\u001b[39m, in \u001b[36mload_llm\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload_llm\u001b[39m():\n\u001b[32m      5\u001b[39m     \u001b[38;5;66;03m# Load the locally downloaded model here\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     llm = \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdeepseek-r1:14b\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mllama\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmax_new_tokens\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m3000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0.01\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcontext_length\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m3000\u001b[39;49m\n\u001b[32m     13\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m llm\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\projects\\pharmabot\\myenv\\Lib\\site-packages\\ctransformers\\hub.py:178\u001b[39m, in \u001b[36mAutoModelForCausalLM.from_pretrained\u001b[39m\u001b[34m(cls, model_path_or_repo_id, model_type, model_file, config, lib, local_files_only, revision, hf, **kwargs)\u001b[39m\n\u001b[32m    167\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m path_type == \u001b[33m\"\u001b[39m\u001b[33mrepo\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    168\u001b[39m     model_path = \u001b[38;5;28mcls\u001b[39m._find_model_path_from_repo(\n\u001b[32m    169\u001b[39m         model_path_or_repo_id,\n\u001b[32m    170\u001b[39m         model_file,\n\u001b[32m    171\u001b[39m         local_files_only=local_files_only,\n\u001b[32m    172\u001b[39m         revision=revision,\n\u001b[32m    173\u001b[39m     )\n\u001b[32m    175\u001b[39m llm = LLM(\n\u001b[32m    176\u001b[39m     model_path=model_path,\n\u001b[32m    177\u001b[39m     model_type=model_type,\n\u001b[32m--> \u001b[39m\u001b[32m178\u001b[39m     config=\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconfig\u001b[49m,\n\u001b[32m    179\u001b[39m     lib=lib,\n\u001b[32m    180\u001b[39m )\n\u001b[32m    181\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m hf:\n\u001b[32m    182\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m llm\n",
      "\u001b[31mAttributeError\u001b[39m: 'dict' object has no attribute 'config'"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from ctransformers import AutoModelForCausalLM\n",
    "\n",
    "def load_llm():\n",
    "    # Load the locally downloaded model here\n",
    "    llm = AutoModelForCausalLM.from_pretrained(\n",
    "        \"deepseek-r1:14b\",\n",
    "        model_type=\"llama\",\n",
    "        config={\n",
    "            'max_new_tokens': 3000,\n",
    "            'temperature': 0.01,\n",
    "            'context_length': 3000\n",
    "        }\n",
    "    )\n",
    "    return llm\n",
    "\n",
    "# Load the LLaMA model\n",
    "model = load_llm()\n",
    "\n",
    "# Read the text file\n",
    "with open('extracted_text.txt', 'r') as file:\n",
    "    text_data = file.read()\n",
    "\n",
    "# Process the text data with the model\n",
    "result = model.generate(text_data)\n",
    "\n",
    "# Print the result\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
