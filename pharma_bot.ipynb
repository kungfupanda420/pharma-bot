{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PENICILLIN\n",
      "PuaN\n",
      "30A\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import easyocr\n",
    "from PIL import Image\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    # Load the image\n",
    "    img = cv2.imread(image_path)\n",
    "    \n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Apply thresholding\n",
    "    _, thresh = cv2.threshold(gray, 150, 255, cv2.THRESH_BINARY_INV)\n",
    "    \n",
    "    # Remove noise\n",
    "    kernel = np.ones((1, 1), np.uint8)\n",
    "    processed_img = cv2.dilate(thresh, kernel, iterations=1)\n",
    "    processed_img = cv2.erode(processed_img, kernel, iterations=1)\n",
    "    \n",
    "    # Save the processed image\n",
    "    processed_image_path = 'processed_image.jpg'\n",
    "    cv2.imwrite(processed_image_path, processed_img)\n",
    "    \n",
    "    return processed_image_path\n",
    "\n",
    "def extract_text_from_image(image_path):\n",
    "    reader = easyocr.Reader(['en'])  # Initialize EasyOCR for English\n",
    "    results = reader.readtext(image_path, detail=0)  # Extract text without bounding box details\n",
    "    return '\\n'.join(results)\n",
    "\n",
    "def save_text_to_file(text, file_path):\n",
    "    with open(file_path, 'w') as file:\n",
    "        file.write(text)\n",
    "\n",
    "# Provide the input image path\n",
    "input_image_path = 'image.png'\n",
    "\n",
    "# Process the image\n",
    "processed_image_path = preprocess_image(input_image_path)\n",
    "extracted_text = extract_text_from_image(processed_image_path)\n",
    "print(extracted_text)\n",
    "\n",
    "# Save the extracted text to a file\n",
    "text_file_path = 'extracted_text.txt'\n",
    "save_text_to_file(extracted_text, text_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pprint import pprint\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_core.output_parsers import JsonOutputParser, StrOutputParser\n",
    "from langchain.schema import Document\n",
    "from langgraph.graph import END, StateGraph\n",
    "from typing_extensions import TypedDict\n",
    "from typing import List\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.embeddings import GPT4AllEmbeddings\n",
    "from langchain_community.document_loaders import FireCrawlLoader\n",
    "from langchain_community.vectorstores.utils import filter_complex_metadata\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.embeddings import GPT4AllEmbeddings\n",
    "from langchain_community.document_loaders import FireCrawlLoader\n",
    "from langchain_community.vectorstores.utils import filter_complex_metadata\n",
    "from langchain.docstore.document import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"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\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# from langchain.prompts import PromptTemplate\n",
    "# from langchain.chains import LLMChain\n",
    "# from langchain_huggingface import HuggingFaceEndpoint\n",
    "\n",
    "# # Set Hugging Face API Token\n",
    "# # os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"your_huggingface_api_key\"  # Replace with your actual key\n",
    "# os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"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\"\n",
    "\n",
    "# # Initialize Hugging Face model\n",
    "# llm = HuggingFaceEndpoint(\n",
    "#     endpoint_url=\"https://api-inference.huggingface.co/models/deepseek-ai/DeepSeek-R1\",\n",
    "#     model_kwargs={\"temperature\": 0.7, \"max_length\": 512}\n",
    "# )\n",
    "\n",
    "# # Define the prompt template\n",
    "# prompt = PromptTemplate(\n",
    "#     template=\"\"\"\n",
    "#     You are a knowledgeable doctor providing clear guidance on a patient's prescribed medicine.\n",
    "    \n",
    "#     Medicine Details:\n",
    "#     {context}\n",
    "    \n",
    "#     User Question: {question}\n",
    "#     \"\"\",\n",
    "#     input_variables=[\"question\", \"context\"]\n",
    "# )\n",
    "\n",
    "# # Ensure LLMChain is initialized properly\n",
    "# chain = LLMChain(prompt=prompt, llm=llm)\n",
    "\n",
    "# # Define user input and sample context\n",
    "# question = \"Is there a possibility to get allergy with this medicine?\"\n",
    "# context = \"This medicine is for cold and flu. It contains paracetamol, which helps reduce fever and body aches.\"\n",
    "\n",
    "# # Get response from LLMChain\n",
    "# result = chain.invoke({\"question\": question, \"context\": context})\n",
    "# print(\"Bot:\", result[\"text\"])  # Extract response text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- import os\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "os.environ[\"GROQ_API_KEY\"] = \"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\"  # Set API key manually\n",
    "\n",
    "llm = ChatGroq(temperature=0, model_name=\"llama-3.2-1b-preview\")\n",
    " -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_groq import ChatGroq\n",
    "# llm = ChatGroq(temperature=0, model_name=\"llama-3.2-1b-preview\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: Good morning, let's discuss your concern about penicillin. As your doctor, I'd like to clarify some aspects of penicillin and its potential allergy risks.\n",
      "\n",
      "Penicillin is a type of antibiotic that belongs to the penicillin group of antibiotics. It's effective against many types of bacteria, including strep throat, pneumonia, and skin infections.\n",
      "\n",
      "Penicillin can cause allergic reactions, but they are relatively rare. However, it's essential to discuss this risk with you, as an allergic reaction to penicillin can be severe and even life-threatening.\n",
      "\n",
      "Possible allergy symptoms to penicillin include:\n",
      "\n",
      "1. Hives or itchy skin\n",
      "2. Swelling of the face, lips, tongue, or throat\n",
      "3. Stomach cramps\n",
      "4. Diarrhea\n",
      "5. Vomiting\n",
      "6. Rapid heartbeat or palpitations\n",
      "\n",
      "In rare cases, penicillin can cause a more severe allergic reaction, such as:\n",
      "\n",
      "1. Anaphylaxis, a life-threatening condition that requires immediate medical attention.\n",
      "2. Blood clotting disorders, such as thrombocytopenia.\n",
      "\n",
      "To minimize the risk of an allergic reaction, I recommend the following:\n",
      "\n",
      "1. Inform me about any previous allergic reactions, including medications, medical conditions, or a history of severe allergic reactions.\n",
      "2. Monitor your urination and bowel movements for any signs of allergic reaction.\n",
      "3. Report any unusual symptoms or discomfort to me immediately.\n",
      "4. Follow the prescribed dosage and administration instructions.\n",
      "\n",
      "As a precautionary measure, I also recommend that you:\n",
      "\n",
      "1. Keep an emergency contact number handy, such as my office phone or a nearby hospital.\n",
      "2. Stay hydrated by drinking plenty of water and other fluids.\n",
      "3. Seek immediate medical attention if you experience any symptoms of an allergic reaction.\n",
      "\n",
      "Please let's discuss this further and address any concerns you may have. If you have any questions or concerns, don't hesitate to ask.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "# Set API key\n",
    "os.environ[\"GROQ_API_KEY\"] = \"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\"\n",
    "\n",
    "# Initialize LLM\n",
    "try:\n",
    "    llm = ChatGroq(temperature=0.8, model_name=\"llama-3.2-1b-preview\")\n",
    "except Exception as e:\n",
    "    print(\"Error initializing ChatGroq:\", e)\n",
    "    exit()\n",
    "\n",
    "# Define the prompt template\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "    You are a knowledgeable doctor providing clear guidance on a patient's prescribed medicine.\n",
    "\n",
    "    Medicine Details:\n",
    "    {context}\n",
    "\n",
    "    User Question: {question}\n",
    "    \"\"\",\n",
    "    input_variables=[\"question\", \"context\"]\n",
    ")\n",
    "\n",
    "# Ensure LLMChain is initialized properly\n",
    "chain = LLMChain(prompt=prompt, llm=llm)\n",
    "\n",
    "# Define user input and sample context\n",
    "question = \"Is there a possibility to get allergy with this medicine?\"\n",
    "context = \"This is a medicine \"+extracted_text\n",
    "\n",
    "# Get response from LLMChain\n",
    "try:\n",
    "    result = chain.invoke({\"question\": question, \"context\": context})\n",
    "    print(\"Bot:\", result[\"text\"])  # Extract response text\n",
    "except Exception as e:\n",
    "    print(\"Error invoking LLMChain:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
